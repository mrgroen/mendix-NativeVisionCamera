diff --git a/node_modules/react-native-vision-camera/ios/CameraView+AVAudioSession.swift b/node_modules/react-native-vision-camera/ios/CameraView+AVAudioSession.swift
index 57d0ed5..fb7bfe6 100644
--- a/node_modules/react-native-vision-camera/ios/CameraView+AVAudioSession.swift
+++ b/node_modules/react-native-vision-camera/ios/CameraView+AVAudioSession.swift
@@ -85,19 +85,18 @@ extension CameraView {
    */
   final func activateAudioSession() {
     ReactLogger.log(level: .info, message: "Activating Audio Session...")
-
     do {
-      try AVAudioSession.sharedInstance().updateCategory(AVAudioSession.Category.playAndRecord,
-                                                         options: [.mixWithOthers,
-                                                                   .allowBluetoothA2DP,
-                                                                   .defaultToSpeaker,
-                                                                   .allowAirPlay])
-
+      let audioSession = AVAudioSession.sharedInstance()
+      try audioSession.setCategory(AVAudioSessionCategoryPlayAndRecord,
+                                              with: [.mixWithOthers,
+                                                        .allowBluetoothA2DP,
+                                                        .defaultToSpeaker,
+                                                        .allowAirPlay])
       if #available(iOS 14.5, *) {
-        // prevents the audio session from being interrupted by a phone call
-        try AVAudioSession.sharedInstance().setPrefersNoInterruptionsFromSystemAlerts(true)
+          // prevents the audio session from being interrupted by a phone call
+          try audioSession.setPrefersNoInterruptionsFromSystemAlerts(true)
       }
-
+      try audioSession.setActive(true)
       audioCaptureSession.startRunning()
     } catch let error as NSError {
       switch error.code {
diff --git a/node_modules/react-native-vision-camera/ios/CameraView+AVCaptureSession.swift b/node_modules/react-native-vision-camera/ios/CameraView+AVCaptureSession.swift
index 5c9b77d..58b6a5e 100644
--- a/node_modules/react-native-vision-camera/ios/CameraView+AVCaptureSession.swift
+++ b/node_modules/react-native-vision-camera/ios/CameraView+AVCaptureSession.swift
@@ -168,12 +168,12 @@ extension CameraView {
           return
         }
 
-        let duration = CMTimeMake(value: 1, timescale: fps)
+        let duration = CMTimeMake(1, Int32(fps))
         device.activeVideoMinFrameDuration = duration
         device.activeVideoMaxFrameDuration = duration
       } else {
-        device.activeVideoMinFrameDuration = CMTime.invalid
-        device.activeVideoMaxFrameDuration = CMTime.invalid
+        device.activeVideoMinFrameDuration = kCMTimeInvalid
+        device.activeVideoMaxFrameDuration = kCMTimeInvalid
       }
       if hdr != nil {
         if hdr == true && !device.activeFormat.isVideoHDRSupported {
diff --git a/node_modules/react-native-vision-camera/ios/CameraView+RecordVideo.swift b/node_modules/react-native-vision-camera/ios/CameraView+RecordVideo.swift
index 0c5807c..84fe094 100644
--- a/node_modules/react-native-vision-camera/ios/CameraView+RecordVideo.swift
+++ b/node_modules/react-native-vision-camera/ios/CameraView+RecordVideo.swift
@@ -202,8 +202,8 @@ extension CameraView: AVCaptureVideoDataOutputSampleBufferDelegate, AVCaptureAud
         recordingSession.appendBuffer(sampleBuffer, type: .video, timestamp: CMSampleBufferGetPresentationTimeStamp(sampleBuffer))
       case is AVCaptureAudioDataOutput:
         let timestamp = CMSyncConvertTime(CMSampleBufferGetPresentationTimeStamp(sampleBuffer),
-                                          from: audioCaptureSession.masterClock ?? CMClockGetHostTimeClock(),
-                                          to: captureSession.masterClock ?? CMClockGetHostTimeClock())
+                                          audioCaptureSession.masterClock ?? CMClockGetHostTimeClock(),
+                                          captureSession.masterClock ?? CMClockGetHostTimeClock())
         recordingSession.appendBuffer(sampleBuffer, type: .audio, timestamp: timestamp)
       default:
         break
diff --git a/node_modules/react-native-vision-camera/ios/CameraView.swift b/node_modules/react-native-vision-camera/ios/CameraView.swift
index e3cd1e0..6a40dcb 100644
--- a/node_modules/react-native-vision-camera/ios/CameraView.swift
+++ b/node_modules/react-native-vision-camera/ios/CameraView.swift
@@ -144,11 +144,11 @@ public final class CameraView: UIView {
                                            object: audioCaptureSession)
     NotificationCenter.default.addObserver(self,
                                            selector: #selector(audioSessionInterrupted),
-                                           name: AVAudioSession.interruptionNotification,
+                                           name: NSNotification.Name.AVAudioSessionInterruption,
                                            object: AVAudioSession.sharedInstance)
     NotificationCenter.default.addObserver(self,
                                            selector: #selector(onOrientationChanged),
-                                           name: UIDevice.orientationDidChangeNotification,
+                                           name: NSNotification.Name.UIDeviceOrientationDidChange,
                                            object: nil)
   }
 
@@ -165,10 +165,10 @@ public final class CameraView: UIView {
                                               name: .AVCaptureSessionRuntimeError,
                                               object: audioCaptureSession)
     NotificationCenter.default.removeObserver(self,
-                                              name: AVAudioSession.interruptionNotification,
+                                              name: NSNotification.Name.AVAudioSessionInterruption,
                                               object: AVAudioSession.sharedInstance)
     NotificationCenter.default.removeObserver(self,
-                                              name: UIDevice.orientationDidChangeNotification,
+                                              name: NSNotification.Name.UIDeviceOrientationDidChange,
                                               object: nil)
   }
 
diff --git a/node_modules/react-native-vision-camera/ios/Extensions/AVAudioSession+updateCategory.swift b/node_modules/react-native-vision-camera/ios/Extensions/AVAudioSession+updateCategory.swift
index c68c743..b3bcc01 100644
--- a/node_modules/react-native-vision-camera/ios/Extensions/AVAudioSession+updateCategory.swift
+++ b/node_modules/react-native-vision-camera/ios/Extensions/AVAudioSession+updateCategory.swift
@@ -14,10 +14,10 @@ extension AVAudioSession {
    Calls [setCategory] if the given category or options are not equal to the currently set category and options.
    */
   func updateCategory(_ category: AVAudioSession.Category, options: AVAudioSession.CategoryOptions = []) throws {
-    if self.category != category || categoryOptions.rawValue != options.rawValue {
+    if self.category as String != category as String || categoryOptions.rawValue != options.rawValue {
       ReactLogger.log(level: .info,
-                      message: "Changing AVAudioSession category from \(self.category.rawValue) -> \(category.rawValue)")
-      try setCategory(category, options: options)
+                      message: "Changing AVAudioSession category from \(self.category as String) -> \(category as String)")
+      try setCategory(category as String, with: options)
     }
   }
 }
diff --git a/node_modules/react-native-vision-camera/ios/Extensions/AVCaptureDevice.Format+videoDimensions.swift b/node_modules/react-native-vision-camera/ios/Extensions/AVCaptureDevice.Format+videoDimensions.swift
index c7571f8..79edf16 100644
--- a/node_modules/react-native-vision-camera/ios/Extensions/AVCaptureDevice.Format+videoDimensions.swift
+++ b/node_modules/react-native-vision-camera/ios/Extensions/AVCaptureDevice.Format+videoDimensions.swift
@@ -17,8 +17,7 @@ extension AVCaptureDevice.Format {
    * Pixel aspect ratio is used to adjust the width, leaving the height alone.
    */
   var videoDimensions: CGSize {
-    return CMVideoFormatDescriptionGetPresentationDimensions(formatDescription,
-                                                             usePixelAspectRatio: true,
-                                                             useCleanAperture: true)
+    let dimensions: CMVideoDimensions = CMVideoFormatDescriptionGetDimensions(formatDescription)
+    return CGSize(width: Int(dimensions.width), height: Int(dimensions.height))
   }
 }
